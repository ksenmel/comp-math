# Задача Дирихле для уравнения Пуассона
## Цель работы
1. Разобраться в параллельном алгоритме 11.6, предложенном в 11 главе книги В. П. Гергеля
   [“Высокопроизводительные вычисления для
   многоядерных многопроцессорных систем” (2010)](https://github.com/artjomjuferov/university/blob/master/Beljakova/Гергель%20В.П.%20Высокопроизводительные%20вычисления%20для%20многоядерных%20многопроцессорных%20систем%20(2010).pdf)
2. Реализовать этот алгоритм c помощью библиотеки OpenMP
3. Сравнить эфективность и время параллельного алгоритма на 1, 8 и 12 потоках, 
4. Узнать, как время исполнения зависит от размера сетки,`EPS` и выбранных функций

## Аппаратное обеспечение
- Процессор — **Apple M2**
- Оперативная память — **8 GB**
- Операционная система — **macOS Ventura 13.0**
- L1 data cache — **64 KB**
- core CPU — **8**
## Программное обеспечение
- OpenMP **4.5**
- GCC **6.1**

## Условия
### Обозначения
- $D$ — область задания функции, для простоты возьмем единичный квадрат. $D ={( x, y) ∈ D : 0 ≤ x, y ≤ 1 }$
- $N$ — размер сетки, т.н `size` в коде
- $k$ — количество итераций
- `BLOCK_SIZE` — размер блока
- `EPS` — допустимая разница между результатом приближения и истинным значением функции

Мы имеем сетку `N × N`. В последовательном алгоритме на вычисления потребуется `N × N` шагов на каждую итерацию, значит для выполнения алгоритма понадобится время $`t \approx i × (C × N^2)`$, где $i$ — количество итераций, $`\ C \in R`$ — время, затраченное на другие операции в алгоритме (приближение результата, синхронизация и т.д). 

В параллельном алгоритме нам нужно обрабатывать блоки размером `BLOCK_SIZE` (далее назовем это `SZ`). Внутри блока алгоритм выполняет последовательные вычисления, а значит каждый блок размером `SZ × SZ` обрабатывается за $`t \approx i × (C × SZ^2)`$. Алгоритм 11.6 основан на обработке "волнами", что включает в себя обработку "нарастания" и "затухания" волны (подробнее об этом в книге). Таким образом, чтоб обработать всю сетку нам понадобится времени:

$`T \approx i × (\displaystyle\sum_{i=1}^{NB} t × block(i/I)×C + \displaystyle\sum_{i=1}^{NB-1} t × block(i/I)×C )`$, 

где  $NB$ — количество блоков в сетке, $I$ — количество потоков, $block(i/I)$ — вычисление $i$ блоков на $I$ потоков. Первое слагаемое — обработка нарастания волны, второе — обработка затухания волны. 

### На каких данных проводились эксперименты:
- $N$ — **100, 300, 500, 1000, 2000**
- `BLOCK_SIZE` — **32, 64**
- `EPS` — **0.1**
### Исследуемые функции для аппроксимации
1. $u(x, y) = 1000x^3 + 2000y^3$, $f(x, y) = 6000x + 12000y$
2. $u(x, y) = e^{xy}$, $f(x, y) = y^2 × e^{xy} + x^2 × e^{xy}$

#### Про выбор функции 
Были выбраны две краевые функции, чье количество итераций и, соответственно, время выполнения сильно отличаются. 
Важно знать, что результаты скорости вычислений не зависят от выбора функций. Об этом подробнее будет в выводе. 

## Результаты и вывод
Численные результаты эксперимента можно увидеть в [таблице](https://docs.google.com/spreadsheets/d/16Lk8SpY3h193Txz-zvt0MLYpKzV5tR5OnCibHUItRNs/edit?usp=sharing). Для замера времени вычисления было проведено 10 экспериментов, выкинуты несколько выбросов и взято среднее. Зеленым помечены наилучшие значения среди исследуемых потоков. 

Можно сделать следующие выводы:
1. Используя алгоритм с распараллеливанием, разница в времени вычисления довольно существенная, если **N >= 300**
2. Выгоднее всего (в терминах времени) параллелить на 8 потоков. Также, на 12 потоках быстрее, чем на 1, но иногда медленнее, чем на 8. Самая очевидная и существенная причина этому - 8 ядер CPU на данной вычислительной машине. Другая же причина в том, что при распараллеливании программы на 12 и более потоков, дополнительные ресурсы тратятся на поддержку параллельной обработки, в частности, на переключение контекста процессора между потоками. Итог: распараллеливание на большое количество потоков не всегда приводит к хорошей производительности
3. При уменьшении `EPS` время выполнения будет дольше. Связано это с тем, что `EPS` задает нам точность вычислений, т.е алгоритм будет продолжать работать, пока изменения значений не станут меньше данного `EPS`
4. В ходе эксперимента было выявлено, что результаты скорости вычислений не зависят от выбора функций. Краевая функция задаёт начальное состояние сетки, что влияет только на количество итераций (а это количество у параллельного и последовательного алгоритма одинаковое), поэтому избирать функции по каким-то "особенным признакам" по типу непрерывности в каких-то отдельных точках не имеет смысла, если это не оговорено в целях эксперимента
5. Выбор блока размером `BLOCK_SIZE` размером 64 оказался эффективнее в вычислениях, чем размер 32. Однако в последовательном алгоритме с малым размером сетки наблюдается обратное.
